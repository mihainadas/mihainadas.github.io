---
layout: post
title: "Simple Perceptron Notebook"
date: 2020-01-04 19:00:00 +0200
tags: machine learning, perceptron
---
The best way to dive into the foundational concepts of machine learning is through a practical implementation of the perceptron algorithm. This notebook builds on Frank Rosenblatt’s seminal 1958 paper, _“The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain”_, and provides a hands-on guide to understanding and implementing this key algorithm.

What You’ll Find in This Notebook:
- Dataset Generation: A custom Python function for creating synthetic datasets for training and testing.
- Visual Representations: Clear visualizations of decision boundaries and data points using Matplotlib.
- Mathematical Foundations: A step-by-step breakdown of how the perceptron works, from weight initialization to the adjustment of parameters based on classification errors.
- Practical Insights: Observations about accuracy, decision boundaries, and how parameter tuning affects classification performance.

Whether you’re just beginning your machine learning journey or revisiting foundational algorithms, this notebook is designed to help you deepen your understanding of perceptrons.

🌐 Available HTML Versions:
- [Perceptron Notebook - English Version](http://mihainadas.github.io/notebooks/perceptron_en.html){:target="_blank"}
- [Perceptron Notebook - Romanian Version](http://mihainadas.github.io/notebooks/perceptron_ro.html){:target="_blank"}

📝 [View the Jupyter Notebook on GitHub](https://github.com/mihainadas/notebooks/blob/main/perceptron.ipynb){:target="_blank"}

I hope you find this resource both informative and engaging! As always, I welcome feedback and questions—feel free to reach out or comment below. Happy learning! 🚀 ￼